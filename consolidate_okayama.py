"""
Consolidate Okayama Factories
==============================
Merge CVJå·¥å ´ and HUBå·¥å ´ into single å²¡å±±å·¥å ´.json
"""

import json
import sys
from pathlib import Path
from datetime import datetime

# Fix encoding for Windows
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# Paths
FACTORIES_DIR = Path("D:/JPUNS-CLAUDE4.2/config/factories")
BACKUP_DIR = FACTORIES_DIR / "backup" / f"before_okayama_consolidation_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

CVJ_FILE = FACTORIES_DIR / "é«˜é›„å·¥æ¥­æ ªå¼ä¼šç¤¾_CVJå·¥å ´.json"
HUB_FILE = FACTORIES_DIR / "é«˜é›„å·¥æ¥­æ ªå¼ä¼šç¤¾_HUBå·¥å ´.json"
OKAYAMA_FILE = FACTORIES_DIR / "é«˜é›„å·¥æ¥­æ ªå¼ä¼šç¤¾_å²¡å±±å·¥å ´.json"

def consolidate_okayama():
    """Consolidate CVJ and HUB factories into single å²¡å±±å·¥å ´"""

    print("=" * 80)
    print("CONSOLIDAR FÃBRICAS DE OKAYAMA")
    print("=" * 80)
    print()

    # Create backup directory
    BACKUP_DIR.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ Backup creado en: {BACKUP_DIR}")
    print()

    # Read CVJ factory
    print(f"ğŸ“– Leyendo: {CVJ_FILE.name}")
    with open(CVJ_FILE, 'r', encoding='utf-8') as f:
        cvj_data = json.load(f)

    # Read HUB factory
    print(f"ğŸ“– Leyendo: {HUB_FILE.name}")
    with open(HUB_FILE, 'r', encoding='utf-8') as f:
        hub_data = json.load(f)

    print()
    print(f"   CVJå·¥å ´: {len(cvj_data.get('lines', []))} lÃ­neas")
    print(f"   HUBå·¥å ´: {len(hub_data.get('lines', []))} lÃ­neas")
    print()

    # Create consolidated structure
    # Use CVJ as base (both have same company, plant location, etc.)
    okayama_data = {
        "factory_id": "é«˜é›„å·¥æ¥­æ ªå¼ä¼šç¤¾_å²¡å±±å·¥å ´",
        "client_company": cvj_data.get("client_company"),
        "plant": {
            "name": "å²¡å±±å·¥å ´",
            "address": cvj_data.get("plant", {}).get("address"),
            "phone": cvj_data.get("plant", {}).get("phone"),
            "responsible": cvj_data.get("plant", {}).get("responsible")
        },
        "lines": [],
        "dispatch_company": cvj_data.get("dispatch_company"),
        "schedule": cvj_data.get("schedule"),
        "payment": cvj_data.get("payment"),
        "agreement": cvj_data.get("agreement")
    }

    # Add all lines from CVJ
    for line in cvj_data.get("lines", []):
        okayama_data["lines"].append(line)

    # Add all lines from HUB
    for line in hub_data.get("lines", []):
        okayama_data["lines"].append(line)

    print(f"âœ… Consolidado: {len(okayama_data['lines'])} lÃ­neas totales")
    print()

    # Backup original files
    import shutil
    shutil.copy2(CVJ_FILE, BACKUP_DIR / CVJ_FILE.name)
    shutil.copy2(HUB_FILE, BACKUP_DIR / HUB_FILE.name)
    print(f"ğŸ’¾ Backup completado:")
    print(f"   {BACKUP_DIR / CVJ_FILE.name}")
    print(f"   {BACKUP_DIR / HUB_FILE.name}")
    print()

    # Write consolidated file
    with open(OKAYAMA_FILE, 'w', encoding='utf-8') as f:
        json.dump(okayama_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… Creado: {OKAYAMA_FILE.name}")
    print()

    # Delete original files
    CVJ_FILE.unlink()
    HUB_FILE.unlink()

    print(f"ğŸ—‘ï¸  Eliminados:")
    print(f"   {CVJ_FILE.name}")
    print(f"   {HUB_FILE.name}")
    print()

    print("=" * 80)
    print("âœ… CONSOLIDACIÃ“N COMPLETADA")
    print("=" * 80)
    print()
    print(f"ğŸ“Š Resultado:")
    print(f"   Archivo nuevo: {OKAYAMA_FILE.name}")
    print(f"   Total lÃ­neas: {len(okayama_data['lines'])}")
    print(f"   Backup en: {BACKUP_DIR}")
    print()
    print("âš ï¸  IMPORTANTE:")
    print("   Los empleados con factory_id='é«˜é›„å·¥æ¥­æ ªå¼ä¼šç¤¾_CVJå·¥å ´' o")
    print("   'é«˜é›„å·¥æ¥­æ ªå¼ä¼šç¤¾_HUBå·¥å ´' deben actualizarse a:")
    print("   'é«˜é›„å·¥æ¥­æ ªå¼ä¼šç¤¾_å²¡å±±å·¥å ´'")
    print()

if __name__ == "__main__":
    consolidate_okayama()
