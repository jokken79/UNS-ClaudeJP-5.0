"""
Import Photos to Candidates Table from Extracted Photo Mappings JSON

This script reads the JSON file generated by extract_access_attachments.py
and updates the candidates table with photo_data_url values.

Usage:
    python import_photos_from_json.py --photos access_photo_mappings.json

Requirements:
    - PostgreSQL running
    - access_photo_mappings.json file (from extract_access_attachments.py)
    - SQLAlchemy, psycopg2
"""

import sys
import os
import json
import logging
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, Any
from dotenv import load_dotenv

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'import_photos_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# PostgreSQL Configuration from environment
POSTGRES_USER = os.getenv('POSTGRES_USER', 'uns_admin')
POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD', '')
POSTGRES_DB = os.getenv('POSTGRES_DB', 'uns_claudejp')
POSTGRES_PORT = os.getenv('POSTGRES_PORT', '5432')

if os.path.exists('/.dockerenv'):
    POSTGRES_HOST = os.getenv('POSTGRES_HOST', 'db')
    logger.info("Running in Docker - using 'db' as hostname")
else:
    POSTGRES_HOST = os.getenv('POSTGRES_HOST', 'localhost')
    logger.info("Running on host - using 'localhost' as hostname")

POSTGRES_URL = f"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}"


def import_photos_from_json(photo_mappings_file: str) -> Dict[str, Any]:
    """
    Import photos from JSON file to PostgreSQL candidates table

    Args:
        photo_mappings_file: Path to JSON file with photo mappings

    Returns:
        Statistics dictionary
    """

    logger.info("=" * 80)
    logger.info("IMPORTING PHOTOS FROM JSON TO POSTGRESQL")
    logger.info("=" * 80)

    # Check if file exists
    if not os.path.exists(photo_mappings_file):
        logger.error(f"Photo mappings file not found: {photo_mappings_file}")
        return {}

    # Load photo mappings
    logger.info(f"\nLoading photo mappings from: {photo_mappings_file}")
    try:
        with open(photo_mappings_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        mappings = data.get('mappings', {})
        stats = data.get('statistics', {})

        logger.info(f"Loaded {len(mappings)} photo mappings")
        logger.info(f"Extraction statistics:")
        logger.info(f"  Total records: {stats.get('total_records')}")
        logger.info(f"  With attachments: {stats.get('with_attachments')}")
        logger.info(f"  Extraction successful: {stats.get('extraction_successful')}")

    except Exception as e:
        logger.error(f"Failed to load photo mappings: {e}")
        return {}

    if not mappings:
        logger.warning("No photo mappings found in file")
        return {}

    # Connect to PostgreSQL
    # Mask password in URL for logging
    safe_url = POSTGRES_URL.replace(f':{POSTGRES_PASSWORD}@', ':****@') if POSTGRES_PASSWORD else POSTGRES_URL
    logger.info(f"\nConnecting to PostgreSQL: {safe_url}")
    try:
        engine = create_engine(POSTGRES_URL)
        Session = sessionmaker(bind=engine)
        db = Session()
    except Exception as e:
        logger.error(f"Failed to connect to PostgreSQL: {e}")
        return {}

    # Statistics
    import_stats = {
        'total_photos': len(mappings),
        'updated': 0,
        'not_found': 0,
        'errors': 0
    }

    # Update candidates with photos
    logger.info(f"\nUpdating {len(mappings)} candidates with photos...")

    for rirekisho_id, photo_data_url in mappings.items():
        try:
            # Update candidate with photo
            sql = text("""
                UPDATE candidates
                SET photo_data_url = :photo_data_url
                WHERE rirekisho_id = :rirekisho_id AND photo_data_url IS NULL
            """)

            result = db.execute(sql, {
                'photo_data_url': photo_data_url,
                'rirekisho_id': rirekisho_id
            })
            db.commit()

            if result.rowcount > 0:
                import_stats['updated'] += 1
                if import_stats['updated'] % 100 == 0:
                    logger.info(f"  Updated: {import_stats['updated']} photos")
            else:
                import_stats['not_found'] += 1
                logger.debug(f"Candidate not found: {rirekisho_id}")

        except Exception as e:
            import_stats['errors'] += 1
            db.rollback()
            logger.error(f"Error updating {rirekisho_id}: {e}")

    db.close()

    # Summary
    logger.info("\n" + "=" * 80)
    logger.info("IMPORT SUMMARY")
    logger.info("=" * 80)
    logger.info(f"Total photos to import:    {import_stats['total_photos']}")
    logger.info(f"Successfully updated:      {import_stats['updated']}")
    logger.info(f"Candidates not found:      {import_stats['not_found']}")
    logger.info(f"Errors:                    {import_stats['errors']}")

    if import_stats['updated'] > 0:
        success_rate = (import_stats['updated'] * 100) // import_stats['total_photos']
        logger.info(f"Success rate:              {success_rate}%")

    logger.info("=" * 80 + "\n")

    return import_stats


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description='Import photos from JSON to PostgreSQL')
    parser.add_argument('--photos', default='access_photo_mappings.json',
                        help='Path to photo mappings JSON file (default: access_photo_mappings.json)')

    args = parser.parse_args()

    # Run import
    import_photos_from_json(args.photos)


if __name__ == '__main__':
    main()
